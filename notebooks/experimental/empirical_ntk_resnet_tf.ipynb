{
  "cells": [
    {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
      "source": [
        "\u003ca href=\"https://colab.research.google.com/github/google/neural-tangents/blob/main/notebooks/experimental/empirical_ntk_resnet_tf.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTt0UNQbk_Td"
      },
      "source": [
        "# Example of computing NTK of a **Tensorflow (Keras)** ResNet50 on ImageNet inputs\n",
        "Warning: computing the NTK in Tensorflow currently appears to have very long compile times (but OK runtime), can be prone to triggering XLA errors, and does not distinguish between trainable and non-trainable parameters of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvXMUSdFjCqq"
      },
      "source": [
        "Tested on NVIDIA A100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxdetCnZH7xE"
      },
      "source": [
        "More examples: \n",
        "\n",
        "\n",
        "*   JAX (Flax):\n",
        "  * [FCN](https://colab.research.google.com/github/google/neural-tangents/blob/main/notebooks/empirical_ntk_fcn.ipynb)\n",
        "  * [ResNet18](https://colab.research.google.com/github/google/neural-tangents/blob/main/notebooks/empirical_ntk_resnet.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl2JyRE1hK-z"
      },
      "source": [
        "# Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx1xr9v5pyl0",
        "outputId": "2de00c45-710c-4115-8e04-3cf3777098dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: A100-SXM4-40GB (UUID: GPU-00d2130b-454e-7677-9b34-bbe78525d972)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlckZChsxTWj",
        "outputId": "b65c517a-e6a1-4d28-df68-c47d36757a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1 MB 8.7 MB/s \n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.0/951.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.7/175.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tf2jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for neural-tangents (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# We need at least jaxlib-0.1.73 to avoid certain CUDA bugs when using `implementation=auto`\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q --upgrade jax[cuda11_cudnn805] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "\n",
        "# TODO(romann): figure out why Colab crashes sometimes if TF is upgraded.\n",
        "!pip install -q git+https://www.github.com/deepmind/tf2jax.git --no-deps\n",
        "!pip install -q frozendict typing-extensions\n",
        "!pip install -q git+https://www.github.com/google/neural-tangents.git --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbW8KVnsPfVd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import neural_tangents as nt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqxnhMKDE2Gf"
      },
      "outputs": [],
      "source": [
        "input_shape = (224, 224, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqVgigfhDoHU"
      },
      "source": [
        "# Tensorflow model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdqBa3OQDf97"
      },
      "outputs": [],
      "source": [
        "def get_model(O: int) -\u003e tf.Module:\n",
        "  return tf.keras.applications.resnet.ResNet50(classes=O, weights=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXqlToEouqSc"
      },
      "source": [
        "# NTK functions declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPh5LGz9JBK_"
      },
      "outputs": [],
      "source": [
        "def get_ntk_fns(O: int):\n",
        "  # Define a TF-Keras ResNet50 with `O` output logits.\n",
        "  f = get_model(O)\n",
        "  f.build((None, *input_shape))\n",
        "  _, params = nt.experimental.get_apply_fn_and_params(f)\n",
        "\n",
        "  kwargs = dict(\n",
        "      f=f,\n",
        "      trace_axes=(),\n",
        "      vmap_axes=0\n",
        "  )\n",
        "\n",
        "  # Different NTK implementations\n",
        "  jacobian_contraction = nt.experimental.empirical_ntk_fn_tf(\n",
        "      **kwargs, implementation=nt.NtkImplementation.JACOBIAN_CONTRACTION)\n",
        "  ntvp = nt.experimental.empirical_ntk_fn_tf(\n",
        "      **kwargs, implementation=nt.NtkImplementation.NTK_VECTOR_PRODUCTS)\n",
        "  str_derivatives = nt.experimental.empirical_ntk_fn_tf(\n",
        "      **kwargs, implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES)\n",
        "  auto = nt.experimental.empirical_ntk_fn_tf(\n",
        "      **kwargs, implementation=nt.NtkImplementation.AUTO)\n",
        "  \n",
        "  return params, (jacobian_contraction, ntvp, str_derivatives, auto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lWFC3QEgao4"
      },
      "source": [
        "# $\\color{blue}O = 8$ logit, batch size $\\color{red}N = 8$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbExWKkUg9ew"
      },
      "source": [
        "Structured derivatives compute NTK fastest. NTK-vector products are actually slower in this setting, due to costly forward pass relative to parameters size, and therefore scales poorly with batch size $\\color{red}N$. While it scales better with $\\color{blue}O$ than other methods, it's not enough to overcome the $\\color{red}N^2$ forward passes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwhIZWqxKTlt",
        "outputId": "3befafda-8780-4fdc-f705-62d3b2925e77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/neural_tangents/experimental/empirical_tf/empirical.py:215: UserWarning: This function is an early proof-of-concept.\n",
            "  warnings.warn('This function is an early proof-of-concept.')\n"
          ]
        }
      ],
      "source": [
        "O = 8\n",
        "N = 8\n",
        "\n",
        "# Input images x\n",
        "x1 = tf.random.normal((N, *input_shape))\n",
        "x2 = tf.random.normal((N, *input_shape))\n",
        "\n",
        "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zObT8WnPggFo",
        "outputId": "399e552e-1f94-4b80-cc2a-f43bc7acde2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Jacobian contraction\n",
        "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
        "print(k_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW9gJJ4qggFp",
        "outputId": "0058e7b6-68a1-4daa-f0c4-e48d260874f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# NTK-vector products\n",
        "k_2 = ntk_fn_ntvp(x1, x2, params)\n",
        "print(k_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFeWnqGQggFp",
        "outputId": "bdf0f87a-e768-4e12-d23a-d377a14894d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Structured derivatives\n",
        "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
        "print(k_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q63v1L1aggFp",
        "outputId": "776b99af-f327-48a8-8ab8-63c62f6fc017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.00024811307, shape=(), dtype=float32) tf.Tensor(0.0005964738, shape=(), dtype=float32) tf.Tensor(0.000839914, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Make sure kernels agree.\n",
        "print(\n",
        "    tf.reduce_max(tf.abs(k_1 - k_2)) / tf.reduce_mean(tf.abs(k_1)), \n",
        "    tf.reduce_max(tf.abs(k_1 - k_3)) / tf.reduce_mean(tf.abs(k_1)),\n",
        "    tf.reduce_max(tf.abs(k_2 - k_3)) / tf.reduce_mean(tf.abs(k_2))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMsFPSOr3DTE",
        "outputId": "2f052256-5dfa-4117-9d9a-b6fc38142ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "impl=1, flops=17815195648.0\n",
            "impl=2, flops=61376139264.0\n",
            "impl=3, flops=17957609472.0\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Selects best method based on FLOPs at first call / compilation.\n",
        "# Takes about 3x more time to compile.\n",
        "# WARNING: due to an XLA issue, currently only works correctly on TPUs!\n",
        "# Wrong FLOPs for CPU/GPU of JITted functions.\n",
        "k_0 = ntk_fn_auto(x1, x2, params)\n",
        "print(k_0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diP7nkBuggFp",
        "outputId": "e7489fdf-9807-4be9-d1ea-5cbfe76b6919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 327 ms per loop\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "%%timeit\n",
        "ntk_fn_jacobian_contraction(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wehCdvi2ggFp",
        "outputId": "6ebde0d2-e181-4efb-cb93-09bea9cf9d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 491 ms per loop\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "%%timeit\n",
        "# Slower - forward pass (FP) is expensive relative to parameters.\n",
        "# Time cost scales poorly with batch size N.\n",
        "ntk_fn_ntvp(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrm53akVggFp",
        "outputId": "ad3293d9-5e6a-475d-90e7-0166c9565013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 199 ms per loop\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "%%timeit\n",
        "# 2X faster!\n",
        "ntk_fn_str_derivatives(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1QtkBqLggFp",
        "outputId": "0dd0f5cd-6d36-4348-c3d1-8f4c0af5e8b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 326 ms per loop\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "%%timeit \n",
        "# On TPU should match the fastest method.\n",
        "# On GPU/CPU, currently is broken, and may not be the fastest.\n",
        "ntk_fn_auto(x1, x2, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1DLRESpXg7L"
      },
      "source": [
        "# $\\color{blue}O = 128$ logits, batch size $\\color{red}N = 1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfoHOoT-gGy6"
      },
      "source": [
        "Both NTK-vector products and Structured derivatives compute NTK faster than Jacobian contraction. NTK-vector products incur no penalty when batch size $\\color{red}N = 1$, and leverage their beneficial scaling with large $\\color{blue}O = 128$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oHBaAmDhBON",
        "outputId": "f4ce0626-0ec8-4431-ea76-a78e00a9bf17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/neural_tangents/experimental/empirical_tf/empirical.py:215: UserWarning: This function is an early proof-of-concept.\n",
            "  warnings.warn('This function is an early proof-of-concept.')\n"
          ]
        }
      ],
      "source": [
        "O = 128\n",
        "N = 1\n",
        "\n",
        "# Input images x\n",
        "x1 = tf.random.normal((N, *input_shape))\n",
        "x2 = tf.random.normal((N, *input_shape))\n",
        "\n",
        "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc1bUvL-KrK9",
        "outputId": "9d9543e4-6378-4bd4-c3e1-ebb1b077b106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Jacobian contraction\n",
        "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
        "print(k_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdNsmnjOKyp0",
        "outputId": "5d72b27a-60c1-478b-acf2-fa93c8e57c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# NTK-vector products\n",
        "k_2 = ntk_fn_ntvp(x1, x2, params)\n",
        "print(k_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw6HL260K26E",
        "outputId": "d46d21ba-b919-45d5-dc53-d2fdb0d8e36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Structured derivatives\n",
        "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
        "print(k_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYG0fV9nOjnd",
        "outputId": "46825172-1a01-4700-9ff6-00044054b818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.016062234, shape=(), dtype=float32) tf.Tensor(0.002566749, shape=(), dtype=float32) tf.Tensor(0.014049936, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Make sure kernels agree.\n",
        "print(\n",
        "    tf.reduce_max(tf.abs(k_1 - k_2)) / tf.reduce_mean(tf.abs(k_1)), \n",
        "    tf.reduce_max(tf.abs(k_1 - k_3)) / tf.reduce_mean(tf.abs(k_1)),\n",
        "    tf.reduce_max(tf.abs(k_2 - k_3)) / tf.reduce_mean(tf.abs(k_2))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyF4M5_HK5Fk",
        "outputId": "8a6c727b-01cf-47e3-dd42-fcdafbeec34a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "impl=1, flops=30326192128.0\n",
            "impl=2, flops=25741133824.0\n",
            "impl=3, flops=30259060736.0\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 29 calls to \u003cfunction convert.\u003clocals\u003e.converted_fun at 0x7f2fde140dd0\u003e triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 29 calls to \u003cfunction convert.\u003clocals\u003e.converted_fun at 0x7f2fde140dd0\u003e triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Selects best method based on FLOPs at first call / compilation.\n",
        "# Takes about 3x more time to compile.\n",
        "# WARNING: due to an XLA issue, currently only works correctly on TPUs!\n",
        "# Wrong FLOPs for CPU/GPU of JITted functions.\n",
        "k_0 = ntk_fn_auto(x1, x2, params)\n",
        "print(k_0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g1IO71LLJlG",
        "outputId": "be843ed9-ecc6-49d0-dc9a-2e78ddc98846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 494 ms per loop\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "%%timeit\n",
        "ntk_fn_jacobian_contraction(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEIPcXYRMys2",
        "outputId": "7c26d989-4e1e-4267-d11f-550f0f89f519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 275 ms per loop\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "%%timeit\n",
        "# 2X faster!\n",
        "ntk_fn_ntvp(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVyUPA8xM1ot",
        "outputId": "1b2ac344-8c75-43c0-df91-5e57d4adf895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 235 ms per loop\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "%%timeit\n",
        "# 2.5X faster!\n",
        "ntk_fn_str_derivatives(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o81r3UHJM34_",
        "outputId": "44ebbabd-39aa-442c-bdaa-c0eea3b0452d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 277 ms per loop\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "%%timeit \n",
        "# On TPU should match the fastest method.\n",
        "# On GPU/CPU, currently is broken, and may not be the fastest.\n",
        "ntk_fn_auto(x1, x2, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh_aFUZFXm_C"
      },
      "source": [
        "# $\\color{blue}O = 1000$ logits, batch size $\\color{red}N = 1$, full NTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rs4KF07fjjv"
      },
      "source": [
        "Structured derivatives allows to compute full $1000\\times 1000$ ImageNet NTK. Other methods run out of memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4MpdSJ7hFsD",
        "outputId": "bc88b6f0-0f65-4ef0-9fb7-83a89a6b7e2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/neural_tangents/experimental/empirical_tf/empirical.py:215: UserWarning: This function is an early proof-of-concept.\n",
            "  warnings.warn('This function is an early proof-of-concept.')\n"
          ]
        }
      ],
      "source": [
        "O = 1000\n",
        "N = 1\n",
        "\n",
        "# Input images x\n",
        "x1 = tf.random.normal((N, *input_shape))\n",
        "x2 = tf.random.normal((N, *input_shape))\n",
        "\n",
        "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynBEtkA7d_2G",
        "outputId": "a0919de1-a73c-4724-f944-229d6ae96c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1, 1000, 1000)\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Structured derivatives - fits in memory!\n",
        "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
        "print(k_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afniv9k2d_2H",
        "outputId": "ff5dca85-e0c8-4280-f614-97621c0a4553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 1.29 s per loop\n"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "%%timeit\n",
        "ntk_fn_str_derivatives(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "4Ou5a6y4zH5Q",
        "outputId": "39606633-c647-48ae-e0b6-fbd5d126c655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "ename": "UnknownError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-30-43ee9476f982\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# NTK-vector products - OOM!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mk_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntk_fn_ntvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---\u003e 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Failed to determine best cudnn convolution algorithm: RESOURCE_EXHAUSTED: Allocating 9437184000 bytes exceeds the memory limit of 4294967296 bytes.\n\nConvolution performance may be suboptimal.  To ignore this failure and try to use a fallback algorithm, use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning. [Op:__inference_converted_fun_1922490]"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# NTK-vector products - OOM!\n",
        "k_2 = ntk_fn_ntvp(x1, x2, params)\n",
        "print(k_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "rjXRalQfd_2G",
        "outputId": "3616ffb4-365f-431b-f95c-fd821279c815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "ename": "UnknownError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-31-ae557f05f951\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Jacobian contraction - OOM!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mk_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntk_fn_jacobian_contraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---\u003e 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Failed to determine best cudnn convolution algorithm: RESOURCE_EXHAUSTED: Allocating 9437184000 bytes exceeds the memory limit of 4294967296 bytes.\n\nConvolution performance may be suboptimal.  To ignore this failure and try to use a fallback algorithm, use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning. [Op:__inference_converted_fun_2051943]"
          ]
        }
      ],
      "source": [
        "# test {\"skip\": true}\n",
        "# Jacobian contraction - OOM!\n",
        "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
        "print(k_1.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "empirical_ntk_resnet_tf.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
