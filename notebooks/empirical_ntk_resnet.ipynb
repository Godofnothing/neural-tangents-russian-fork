{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otnqBdyaYBrf"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/google/neural-tangents/blob/main/notebooks/empirical_ntk_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTt0UNQbk_Td"
   },
   "source": [
    "# Example of computing NTK of a ResNet18 on ImageNet inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvXMUSdFjCqq"
   },
   "source": [
    "Tested on NVIDIA V100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sl2JyRE1hK-z"
   },
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1655440222004,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "HunkuGjSr63O",
    "outputId": "4693d860-68b5-411c-ca68-489ed1ce237e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1655440222264,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "bmmbCtfh76RS",
    "outputId": "88403900-70b5-4a42-ac1a-6fcf01099b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 1: pip: command not found\n",
      "/bin/sh: line 1: pip: command not found\n",
      "/bin/sh: line 1: pip: command not found\n"
     ]
    }
   ],
   "source": [
    "# We need at least jaxlib-0.1.73 to avoid certain CUDA bugs when using `implementation=auto`\n",
    "!pip install --upgrade pip\n",
    "!pip install jax[cuda11_cudnn805] -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "!pip install -q git+https://github.com/google/flax\n",
    "!pip install -q git+https://www.github.com/google/neural-tangents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gkWtXVMD1MT"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Any, Callable, Sequence, Tuple, Optional\n",
    "from flax import linen as nn\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "from jax import jit\n",
    "from jax import numpy as np\n",
    "from jax import random\n",
    "\n",
    "import neural_tangents as nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNMGKyttrRkC"
   },
   "source": [
    "# ResNet18 definition, copied from [FLAX examples](https://github.com/google/flax/blob/main/examples/imagenet/models.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HG2K1ls5ynG"
   },
   "outputs": [],
   "source": [
    "_ModuleDef = Any\n",
    "\n",
    "\n",
    "class _ResNetBlock(nn.Module):\n",
    "  \"\"\"ResNet block.\"\"\"\n",
    "  filters: int\n",
    "  conv: _ModuleDef\n",
    "  norm: _ModuleDef\n",
    "  act: Callable\n",
    "  strides: Tuple[int, int] = (1, 1)\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x,):\n",
    "    residual = x\n",
    "    y = self.conv(self.filters, (3, 3), self.strides)(x)\n",
    "    y = self.norm()(y)\n",
    "    y = self.act(y)\n",
    "    y = self.conv(self.filters, (3, 3))(y)\n",
    "    y = self.norm(scale_init=nn.initializers.zeros)(y)\n",
    "\n",
    "    if residual.shape != y.shape:\n",
    "      residual = self.conv(self.filters, (1, 1),\n",
    "                           self.strides, name='conv_proj')(residual)\n",
    "      residual = self.norm(name='norm_proj')(residual)\n",
    "\n",
    "    return self.act(residual + y)\n",
    "\n",
    "\n",
    "class _BottleneckResNetBlock(nn.Module):\n",
    "  \"\"\"Bottleneck ResNet block.\"\"\"\n",
    "  filters: int\n",
    "  conv: _ModuleDef\n",
    "  norm: _ModuleDef\n",
    "  act: Callable\n",
    "  strides: Tuple[int, int] = (1, 1)\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    residual = x\n",
    "    y = self.conv(self.filters, (1, 1))(x)\n",
    "    y = self.norm()(y)\n",
    "    y = self.act(y)\n",
    "    y = self.conv(self.filters, (3, 3), self.strides)(y)\n",
    "    y = self.norm()(y)\n",
    "    y = self.act(y)\n",
    "    y = self.conv(self.filters * 4, (1, 1))(y)\n",
    "    y = self.norm(scale_init=nn.initializers.zeros)(y)\n",
    "\n",
    "    if residual.shape != y.shape:\n",
    "      residual = self.conv(self.filters * 4, (1, 1),\n",
    "                           self.strides, name='conv_proj')(residual)\n",
    "      residual = self.norm(name='norm_proj')(residual)\n",
    "\n",
    "    return self.act(residual + y)\n",
    "\n",
    "\n",
    "class _ResNet(nn.Module):\n",
    "  \"\"\"ResNetV1.\"\"\"\n",
    "  stage_sizes: Sequence[int]\n",
    "  block_cls: _ModuleDef\n",
    "  num_classes: int\n",
    "  num_filters: int = 64\n",
    "  dtype: Any = np.float32\n",
    "  act: Callable = nn.relu\n",
    "  conv: _ModuleDef = nn.Conv\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x, train: bool = True):\n",
    "    conv = partial(self.conv, use_bias=False, dtype=self.dtype)\n",
    "    norm = partial(nn.BatchNorm,\n",
    "                   use_running_average=not train,\n",
    "                   momentum=0.9,\n",
    "                   epsilon=1e-5,\n",
    "                   dtype=self.dtype)\n",
    "\n",
    "    x = conv(self.num_filters, (7, 7), (2, 2),\n",
    "             padding=[(3, 3), (3, 3)],\n",
    "             name='conv_init')(x)\n",
    "    x = norm(name='bn_init')(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.max_pool(x, (3, 3), strides=(2, 2), padding='SAME')\n",
    "    for i, block_size in enumerate(self.stage_sizes):\n",
    "      for j in range(block_size):\n",
    "        strides = (2, 2) if i > 0 and j == 0 else (1, 1)\n",
    "        x = self.block_cls(self.num_filters * 2 ** i,\n",
    "                           strides=strides,\n",
    "                           conv=conv,\n",
    "                           norm=norm,\n",
    "                           act=self.act)(x)\n",
    "    x = np.mean(x, axis=(1, 2))\n",
    "    x = nn.Dense(self.num_classes, dtype=self.dtype)(x)\n",
    "    x = np.asarray(x, self.dtype)\n",
    "    return x\n",
    "\n",
    "\n",
    "_ResNet18 = partial(_ResNet, stage_sizes=[2, 2, 2, 2],\n",
    "                    block_cls=_ResNetBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPh5LGz9JBK_"
   },
   "outputs": [],
   "source": [
    "def get_ntk_fns(O: int):\n",
    "  # Define a ResNet18.\n",
    "  model = _ResNet18(num_classes=O)\n",
    "\n",
    "  # f(x, \\theta)\n",
    "  def apply_fn(params, x):\n",
    "    return model.apply(params, x, train=False, mutable=['batch_stats'])[0]\n",
    "\n",
    "  kwargs = dict(\n",
    "      f=apply_fn,\n",
    "      trace_axes=(),\n",
    "      vmap_axes=0\n",
    "  )\n",
    "\n",
    "  # Different NTK implementations\n",
    "  jacobian_contraction = jit(nt.empirical_ntk_fn(**kwargs, implementation=1))\n",
    "  ntvp = jit(nt.empirical_ntk_fn(**kwargs, implementation=2))\n",
    "  str_derivatives = jit(nt.empirical_ntk_fn(**kwargs, implementation=3))\n",
    "  auto = jit(nt.empirical_ntk_fn(**kwargs, implementation=0))\n",
    "\n",
    "  # Parameters \\theta\n",
    "  params = model.init(random.PRNGKey(0), x1)\n",
    "  return params, (jacobian_contraction, ntvp, str_derivatives, auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lWFC3QEgao4"
   },
   "source": [
    "# $\\color{blue}O = 8$ logit, batch size $\\color{red}N = 8$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbExWKkUg9ew"
   },
   "source": [
    "Structured derivatives compute NTK fastest. NTK-vector products are actually slower in this setting, due to costly forward pass relative to parameters size, and therefore scales poorly with batch size $\\color{red}N$. While it scales better with $\\color{blue}O$ than other methods, it's not enough to overcome the $\\color{red}N^2$ forward passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwhIZWqxKTlt"
   },
   "outputs": [],
   "source": [
    "O = 8\n",
    "N = 8\n",
    "\n",
    "# Input images x\n",
    "input_shape = (224, 224, 3)\n",
    "k1, k2 = random.split(random.PRNGKey(1), 2)\n",
    "x1 = random.normal(k1, (N, *input_shape))\n",
    "x2 = random.normal(k2, (N, *input_shape))\n",
    "\n",
    "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17688,
     "status": "ok",
     "timestamp": 1655440254995,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "zObT8WnPggFo",
    "outputId": "8737520d-7b3d-49a9-8fd7-8e37b050e15d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# Jacobian contraction\n",
    "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
    "print(k_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17248,
     "status": "ok",
     "timestamp": 1655440272384,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "FW9gJJ4qggFp",
    "outputId": "999f71a4-5f01-473d-993f-2a890de13726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# NTK-vector products\n",
    "k_2 = ntk_fn_ntvp(x1, x2, params)\n",
    "print(k_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15789,
     "status": "ok",
     "timestamp": 1655440288316,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "gFeWnqGQggFp",
    "outputId": "7e329908-35df-4018-809b-f80e261eb0c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "# Structured derivatives\n",
    "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
    "print(k_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1655440288799,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "Q63v1L1aggFp",
    "outputId": "d990ebab-9cc9-48e5-c88d-02732fe670a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4810557e-06 3.4810557e-06 3.916188e-06\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# Make sure kernels agree.\n",
    "print(\n",
    "    np.max(np.abs(k_1 - k_2)) / np.mean(np.abs(k_1)),\n",
    "    np.max(np.abs(k_1 - k_3)) / np.mean(np.abs(k_1)),\n",
    "    np.max(np.abs(k_2 - k_3)) / np.mean(np.abs(k_2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43983,
     "status": "ok",
     "timestamp": 1655440332922,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "Ux7AEZ9fggFp",
    "outputId": "666740c2-952d-4f10-c63a-a9e24fdb57f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impl=1, flops=3964546560.0\n",
      "impl=2, flops=20214009856.0\n",
      "impl=3, flops=4047975424.0\n",
      "(8, 8, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# Selects best method based on FLOPs at first call / compilation.\n",
    "# Takes about 3x more time to compile.\n",
    "# WARNING: due to an XLA issue, currently only works correctly on TPUs!\n",
    "# Wrong FLOPs for CPU/GPU of JITted functions.\n",
    "k_0 = ntk_fn_auto(x1, x2, params)\n",
    "print(k_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1655440334474,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "diP7nkBuggFp",
    "outputId": "bc6d84a7-8ecd-457e-a9b2-c028b7be7f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 5: 224 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "%%timeit\n",
    "ntk_fn_jacobian_contraction(x1, x2, params).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2040,
     "status": "ok",
     "timestamp": 1655440336662,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "wehCdvi2ggFp",
    "outputId": "3bafb1bb-9b8e-47fb-dad9-9ddc00087179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 5: 329 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "%%timeit\n",
    "# Slower - forward pass (FP) is expensive relative to parameters.\n",
    "# Time cost scales poorly with batch size N.\n",
    "ntk_fn_ntvp(x1, x2, params).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6380,
     "status": "ok",
     "timestamp": 1655440343191,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "Yrm53akVggFp",
    "outputId": "1950a9c1-3a9e-454e-a982-b8b8eef84654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 103 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "%%timeit\n",
    "# 2X faster.\n",
    "ntk_fn_str_derivatives(x1, x2, params).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1415,
     "status": "ok",
     "timestamp": 1655440344757,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "P1QtkBqLggFp",
    "outputId": "7be26791-18f5-4032-ef77-2203a755b992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 5: 224 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "%%timeit\n",
    "# On TPU should match the fastest method.\n",
    "# On GPU/CPU, currently is broken, and may not be the fastest.\n",
    "ntk_fn_auto(x1, x2, params).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1DLRESpXg7L"
   },
   "source": [
    "# $\\color{blue}O = 128$ logits, batch size $\\color{red}N = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfoHOoT-gGy6"
   },
   "source": [
    "Both NTK-vector products and Structured derivatives compute NTK faster than Jacobian contraction. NTK-vector products incur no penalty when batch size $\\color{red}N = 1$, and leverage their beneficial scaling with large $\\color{blue}O = 128$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oHBaAmDhBON"
   },
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "O = 128\n",
    "N = 1\n",
    "\n",
    "# Input images x\n",
    "input_shape = (224, 224, 3)\n",
    "k1, k2 = random.split(random.PRNGKey(1), 2)\n",
    "x1 = random.normal(k1, (N, *input_shape))\n",
    "x2 = random.normal(k2, (N, *input_shape))\n",
    "\n",
    "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20977,
     "status": "ok",
     "timestamp": 1655440369067,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "sc1bUvL-KrK9",
    "outputId": "3af639c6-5fe5-46c7-d05a-969524c6b3c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# Jacobian contraction\n",
    "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
    "print(k_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12760,
     "status": "ok",
     "timestamp": 1655440381956,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "qdNsmnjOKyp0",
    "outputId": "ae59683d-bf3b-4f67-921a-058f9ecd41d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# NTK-vector products\n",
    "k_2 = ntk_fn_ntvp(x1, x2, params)\n",
    "print(k_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13354,
     "status": "ok",
     "timestamp": 1655440395458,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "Iw6HL260K26E",
    "outputId": "ce62e724-ea7b-4f71-e1a2-2ade004f5ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# Structured derivatives\n",
    "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
    "print(k_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1655440395825,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "DYG0fV9nOjnd",
    "outputId": "b9bd3d99-6223-4795-ea50-fc9c757337a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.637553e-05 1.0234707e-05 1.2281647e-05\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# Make sure kernels agree.\n",
    "print(\n",
    "    np.max(np.abs(k_1 - k_2)) / np.mean(np.abs(k_1)),\n",
    "    np.max(np.abs(k_1 - k_3)) / np.mean(np.abs(k_1)),\n",
    "    np.max(np.abs(k_2 - k_3)) / np.mean(np.abs(k_2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41082,
     "status": "ok",
     "timestamp": 1655440437056,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "DyF4M5_HK5Fk",
    "outputId": "e813c6b2-4ca7-49f3-f563-fd0eb12cba29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impl=1, flops=6864192000.0\n",
      "impl=2, flops=7510226432.0\n",
      "impl=3, flops=6847879168.0\n",
      "(1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# Selects best method based on FLOPs at first call / compilation.\n",
    "# Takes about 3x more time to compile.\n",
    "# WARNING: due to an XLA issue, currently only works correctly on TPUs!\n",
    "# Wrong FLOPs for CPU/GPU of JITted functions.\n",
    "k_0 = ntk_fn_auto(x1, x2, params)\n",
    "print(k_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2798,
     "status": "ok",
     "timestamp": 1655440440016,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "8g1IO71LLJlG",
    "outputId": "cc7db073-3ff6-4e74-8c8a-1e54b6d50b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 5: 454 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "%%timeit\n",
    "ntk_fn_jacobian_contraction(x1, x2, params).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8991,
     "status": "ok",
     "timestamp": 1655440449164,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "KEIPcXYRMys2",
    "outputId": "dd65a954-ead4-4e81-9a90-288afece2a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 146 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "%%timeit\n",
    "# 3X faster!\n",
    "ntk_fn_ntvp(x1, x2, params).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6918,
     "status": "ok",
     "timestamp": 1655440456244,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "gVyUPA8xM1ot",
    "outputId": "d417b26b-2eb3-44c7-af78-9463dc394711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 112 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "%%timeit\n",
    "# 4X faster!\n",
    "ntk_fn_str_derivatives(x1, x2, params).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7074,
     "status": "ok",
     "timestamp": 1655440463465,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "o81r3UHJM34_",
    "outputId": "ffeac3bb-1ff9-431e-f5d1-3adb5b42fca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 112 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "%%timeit\n",
    "# On TPU should match the fastest method.\n",
    "# On GPU/CPU, currently is broken, and may not be the fastest.\n",
    "ntk_fn_auto(x1, x2, params).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh_aFUZFXm_C"
   },
   "source": [
    "# $\\color{blue}O = 1000$ logits, batch size $\\color{red}N = 1$, full NTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rs4KF07fjjv"
   },
   "source": [
    "Structured derivatives allows to compute full $1000\\times 1000$ ImageNet NTK. Other methods run out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4MpdSJ7hFsD"
   },
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "O = 1000\n",
    "N = 1\n",
    "\n",
    "# Input images x\n",
    "input_shape = (224, 224, 3)\n",
    "k1, k2 = random.split(random.PRNGKey(1), 2)\n",
    "x1 = random.normal(k1, (N, *input_shape))\n",
    "x2 = random.normal(k2, (N, *input_shape))\n",
    "\n",
    "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25580,
     "status": "ok",
     "timestamp": 1655440489899,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "ynBEtkA7d_2G",
    "outputId": "5cf3fe25-edfe-4e92-bb20-12ba6f9c4ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# Structured derivatives - fits in memory!\n",
    "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
    "print(k_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6622,
     "status": "ok",
     "timestamp": 1655440496675,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "Afniv9k2d_2H",
    "outputId": "0002f0b7-a297-49ba-a412-dc03b3d79f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 5: 975 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "%%timeit\n",
    "ntk_fn_str_derivatives(x1, x2, params).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 901
    },
    "executionInfo": {
     "elapsed": 8754,
     "status": "error",
     "timestamp": 1655440505574,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "4Ou5a6y4zH5Q",
    "outputId": "43c3cb51-0af4-4ea8-e293-84be80213770"
   },
   "outputs": [
    {
     "debug": {
      "argv": [
       "/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook",
       "kernel",
       "-f",
       "/tmp/ipy-be-7o0upqji/profile_colab/security/kernel-4aedcd4b-83cf-40ca-b6c7-0183d68416cd.json",
       "--profile-dir",
       "/tmp/ipy-be-7o0upqji/profile_colab",
       "--profile=colab",
       "--ipython-dir=/tmp/ipy-be-340cs219",
       "--no-secure"
      ],
      "build": "Built on Tue Jun 14 18:56:34 2022 (1655258194)\nBuilt by brain-frameworks-releaser@jxbcq2.prod.google.com:/google/src/cloud/buildrabbit-username/buildrabbit-client/google3\nBuilt as //learning/deepmind/public/tools/ml_python:ml_notebook\nBuild ID: 87dba737-192f-473c-a2ee-1bf81b1aa71c\nBuilt from changelist 454988202 in a mint client based on //depot/google3\nBuild label: ml_notebook_no_par_mpm_2022-06-14-18_00_RC00\nBuild platform: gcc-4.X.Y-crosstool-v18-llvm-grtev4-k8\nBuild tool: Blaze, release blaze-2022.06.08-2 (mainline @453528249)\nBuilt with par options [--compress, --compress]\nCurrently running under Python 3.9.12: embedded.\n",
      "user": "romann"
     },
     "ename": "XlaRuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnfilteredStackTrace\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-51-883de596a9ae>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# NTK-vector products - OOM!\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mk_3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mntk_fn_ntvp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mk_3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/traceback_util.py\u001B[0m in \u001B[0;36mreraise_with_filtered_traceback\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    161\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 162\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    163\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/api.py\u001B[0m in \u001B[0;36mcache_miss\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    521\u001B[0m       \u001B[0mflat_fun\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlu\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mannotate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mflat_fun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0min_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 522\u001B[1;33m     out_flat = xla.xla_call(\n\u001B[0m\u001B[0;32m    523\u001B[0m         \u001B[0mflat_fun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs_flat\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/core.py\u001B[0m in \u001B[0;36mbind\u001B[1;34m(self, fun, *args, **params)\u001B[0m\n\u001B[0;32m   1788\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mbind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1789\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mcall_bind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1790\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/core.py\u001B[0m in \u001B[0;36mcall_bind\u001B[1;34m(primitive, fun, *args, **params)\u001B[0m\n\u001B[0;32m   1804\u001B[0m   \u001B[0mfun_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlu\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mannotate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfun_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0min_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1805\u001B[1;33m   \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtop_trace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprimitive\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtracers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1806\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfull_lower\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mapply_todos\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0menv_trace_todo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mouts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/core.py\u001B[0m in \u001B[0;36mprocess_call\u001B[1;34m(self, primitive, f, tracers, params)\u001B[0m\n\u001B[0;32m    678\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mprocess_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprimitive\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtracers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 679\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mprimitive\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimpl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mtracers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    680\u001B[0m   \u001B[0mprocess_map\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprocess_call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36m_xla_call_impl\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    195\u001B[0m   \u001B[0marg_specs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0munsafe_map\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg_spec\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m   compiled_fun = xla_callable(fun, device, backend, name, donated_invars,\n\u001B[0m\u001B[0;32m    197\u001B[0m                               keep_unused, *arg_specs)\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/linear_util.py\u001B[0m in \u001B[0;36mmemoized_fun\u001B[1;34m(fun, *args)\u001B[0m\n\u001B[0;32m    285\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 286\u001B[1;33m       \u001B[0mans\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    287\u001B[0m       \u001B[0mcache\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mans\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstores\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36m_xla_callable_uncached\u001B[1;34m(fun, device, backend, name, donated_invars, keep_unused, *arg_specs)\u001B[0m\n\u001B[0;32m    244\u001B[0m                            donated_invars, keep_unused, *arg_specs):\n\u001B[1;32m--> 245\u001B[1;33m   return lower_xla_callable(fun, device, backend, name, donated_invars, False,\n\u001B[0m\u001B[0;32m    246\u001B[0m                             keep_unused, *arg_specs).compile().unsafe_call\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36mcompile\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    796\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 797\u001B[1;33m         self._executable = XlaCompiledComputation.from_xla_computation(\n\u001B[0m\u001B[0;32m    798\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_hlo\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_out_type\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36mfrom_xla_computation\u001B[1;34m(name, xla_computation, in_type, out_type, nreps, device, backend, tuple_args, in_avals, out_avals, has_unordered_effects, ordered_effects, kept_var_idx, keepalive)\u001B[0m\n\u001B[0;32m    899\u001B[0m                           \"in {elapsed_time} sec\"):\n\u001B[1;32m--> 900\u001B[1;33m       \u001B[0mcompiled\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompile_or_get_cached\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbackend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxla_computation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    901\u001B[0m     \u001B[0mbuffer_counts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0maval_to_num_buffers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maval\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0maval\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mout_avals\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36mcompile_or_get_cached\u001B[1;34m(backend, computation, compile_options)\u001B[0m\n\u001B[0;32m    860\u001B[0m     \u001B[0m_dump_ir_to_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mir_str\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 861\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mbackend_compile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbackend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcomputation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompile_options\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    862\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/profiler.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    296\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mTraceAnnotation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mdecorator_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 297\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    298\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36mbackend_compile\u001B[1;34m(backend, built_c, options)\u001B[0m\n\u001B[0;32m    806\u001B[0m   \u001B[1;31m# separately in Python profiling results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 807\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbuilt_c\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompile_options\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    808\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnfilteredStackTrace\u001B[0m: google3.third_party.tensorflow.compiler.xla.python.xla_extension.XlaRuntimeError: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter = (f32[3,3,512,512000]{1,0,2,3}, u8[0]{0}) custom-call(f32[1,7,7,512]{2,1,3,0} %bitcast.332, f32[1,7,7,512000]{2,1,3,0} %bitcast.787), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(ntk_fn)/jit(main)/vmap(vmap(vmap(transpose(jvp(_ResNet)))))/_ResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(1, 7, 7, 512) rhs_shape=(1, 7, 7, 512000) precision=None preferred_element_type=None]\" source_file=\"third_party/py/flax/linen/linear.py\" source_line=411}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: INTERNAL: Failed to launch CUDA kernel: redzone_checker with block dimensions: 1024x1x1 and grid dimensions: 8192x1x1: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mXlaRuntimeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-51-883de596a9ae>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# NTK-vector products - OOM!\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mk_3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mntk_fn_ntvp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mk_3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mXlaRuntimeError\u001B[0m: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter = (f32[3,3,512,512000]{1,0,2,3}, u8[0]{0}) custom-call(f32[1,7,7,512]{2,1,3,0} %bitcast.332, f32[1,7,7,512000]{2,1,3,0} %bitcast.787), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(ntk_fn)/jit(main)/vmap(vmap(vmap(transpose(jvp(_ResNet)))))/_ResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(1, 7, 7, 512) rhs_shape=(1, 7, 7, 512000) precision=None preferred_element_type=None]\" source_file=\"third_party/py/flax/linen/linear.py\" source_line=411}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: INTERNAL: Failed to launch CUDA kernel: redzone_checker with block dimensions: 1024x1x1 and grid dimensions: 8192x1x1: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning."
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# NTK-vector products - OOM!\n",
    "k_3 = ntk_fn_ntvp(x1, x2, params)\n",
    "print(k_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 936
    },
    "executionInfo": {
     "elapsed": 8137,
     "status": "error",
     "timestamp": 1655440520245,
     "user": {
      "displayName": "Roman Novak",
      "userId": "09332964040061052680"
     },
     "user_tz": 420
    },
    "id": "rjXRalQfd_2G",
    "outputId": "efffe39d-8597-46d1-cb90-bef878f9d88a"
   },
   "outputs": [
    {
     "debug": {
      "argv": [
       "/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook",
       "kernel",
       "-f",
       "/tmp/ipy-be-7o0upqji/profile_colab/security/kernel-4aedcd4b-83cf-40ca-b6c7-0183d68416cd.json",
       "--profile-dir",
       "/tmp/ipy-be-7o0upqji/profile_colab",
       "--profile=colab",
       "--ipython-dir=/tmp/ipy-be-340cs219",
       "--no-secure"
      ],
      "build": "Built on Tue Jun 14 18:56:34 2022 (1655258194)\nBuilt by brain-frameworks-releaser@jxbcq2.prod.google.com:/google/src/cloud/buildrabbit-username/buildrabbit-client/google3\nBuilt as //learning/deepmind/public/tools/ml_python:ml_notebook\nBuild ID: 87dba737-192f-473c-a2ee-1bf81b1aa71c\nBuilt from changelist 454988202 in a mint client based on //depot/google3\nBuild label: ml_notebook_no_par_mpm_2022-06-14-18_00_RC00\nBuild platform: gcc-4.X.Y-crosstool-v18-llvm-grtev4-k8\nBuild tool: Blaze, release blaze-2022.06.08-2 (mainline @453528249)\nBuilt with par options [--compress, --compress]\nCurrently running under Python 3.9.12: embedded.\n",
      "user": "romann"
     },
     "ename": "XlaRuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnfilteredStackTrace\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-52-2e028af23953>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Jacobian contraction - OOM!\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mk_1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mntk_fn_jacobian_contraction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mk_1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/traceback_util.py\u001B[0m in \u001B[0;36mreraise_with_filtered_traceback\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    161\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 162\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    163\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/api.py\u001B[0m in \u001B[0;36mcache_miss\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    521\u001B[0m       \u001B[0mflat_fun\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlu\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mannotate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mflat_fun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0min_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 522\u001B[1;33m     out_flat = xla.xla_call(\n\u001B[0m\u001B[0;32m    523\u001B[0m         \u001B[0mflat_fun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs_flat\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/core.py\u001B[0m in \u001B[0;36mbind\u001B[1;34m(self, fun, *args, **params)\u001B[0m\n\u001B[0;32m   1788\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mbind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1789\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mcall_bind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1790\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/core.py\u001B[0m in \u001B[0;36mcall_bind\u001B[1;34m(primitive, fun, *args, **params)\u001B[0m\n\u001B[0;32m   1804\u001B[0m   \u001B[0mfun_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlu\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mannotate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfun_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0min_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1805\u001B[1;33m   \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtop_trace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprimitive\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtracers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1806\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfull_lower\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mapply_todos\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0menv_trace_todo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mouts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/core.py\u001B[0m in \u001B[0;36mprocess_call\u001B[1;34m(self, primitive, f, tracers, params)\u001B[0m\n\u001B[0;32m    678\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mprocess_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprimitive\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtracers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 679\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mprimitive\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimpl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mtracers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    680\u001B[0m   \u001B[0mprocess_map\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprocess_call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36m_xla_call_impl\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    195\u001B[0m   \u001B[0marg_specs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0munsafe_map\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg_spec\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m   compiled_fun = xla_callable(fun, device, backend, name, donated_invars,\n\u001B[0m\u001B[0;32m    197\u001B[0m                               keep_unused, *arg_specs)\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/linear_util.py\u001B[0m in \u001B[0;36mmemoized_fun\u001B[1;34m(fun, *args)\u001B[0m\n\u001B[0;32m    285\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 286\u001B[1;33m       \u001B[0mans\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    287\u001B[0m       \u001B[0mcache\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mans\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstores\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36m_xla_callable_uncached\u001B[1;34m(fun, device, backend, name, donated_invars, keep_unused, *arg_specs)\u001B[0m\n\u001B[0;32m    244\u001B[0m                            donated_invars, keep_unused, *arg_specs):\n\u001B[1;32m--> 245\u001B[1;33m   return lower_xla_callable(fun, device, backend, name, donated_invars, False,\n\u001B[0m\u001B[0;32m    246\u001B[0m                             keep_unused, *arg_specs).compile().unsafe_call\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36mcompile\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    796\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 797\u001B[1;33m         self._executable = XlaCompiledComputation.from_xla_computation(\n\u001B[0m\u001B[0;32m    798\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_hlo\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_out_type\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36mfrom_xla_computation\u001B[1;34m(name, xla_computation, in_type, out_type, nreps, device, backend, tuple_args, in_avals, out_avals, has_unordered_effects, ordered_effects, kept_var_idx, keepalive)\u001B[0m\n\u001B[0;32m    899\u001B[0m                           \"in {elapsed_time} sec\"):\n\u001B[1;32m--> 900\u001B[1;33m       \u001B[0mcompiled\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompile_or_get_cached\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbackend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxla_computation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    901\u001B[0m     \u001B[0mbuffer_counts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0maval_to_num_buffers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maval\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0maval\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mout_avals\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36mcompile_or_get_cached\u001B[1;34m(backend, computation, compile_options)\u001B[0m\n\u001B[0;32m    860\u001B[0m     \u001B[0m_dump_ir_to_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mir_str\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 861\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mbackend_compile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbackend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcomputation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompile_options\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    862\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/profiler.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    296\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mTraceAnnotation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mdecorator_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 297\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    298\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m/export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_brain_frameworks_gpu_romann.kernel.romann.3510046706155.14b334fb3717c109/mount/server/ml_notebook.runfiles/google3/third_party/py/jax/_src/dispatch.py\u001B[0m in \u001B[0;36mbackend_compile\u001B[1;34m(backend, built_c, options)\u001B[0m\n\u001B[0;32m    806\u001B[0m   \u001B[1;31m# separately in Python profiling results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 807\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbuilt_c\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompile_options\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    808\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnfilteredStackTrace\u001B[0m: google3.third_party.tensorflow.compiler.xla.python.xla_extension.XlaRuntimeError: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter = (f32[3,3,512,512000]{1,0,2,3}, u8[0]{0}) custom-call(f32[1,7,7,512]{2,1,3,0} %bitcast.566, f32[1,7,7,512000]{2,1,3,0} %bitcast.1618), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(ntk_fn)/jit(main)/vmap(vmap(transpose(jvp(_ResNet))))/_ResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(1, 7, 7, 512) rhs_shape=(1, 7, 7, 512000) precision=None preferred_element_type=None]\" source_file=\"third_party/py/flax/linen/linear.py\" source_line=411}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: INTERNAL: Failed to synchronize GPU for autotuning conv instruction: (f32[3,3,512,512000]{1,0,2,3}, u8[0]{0}) custom-call(f32[1,7,7,512]{2,1,3,0}, f32[1,7,7,512000]{2,1,3,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mXlaRuntimeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-52-2e028af23953>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Jacobian contraction - OOM!\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mk_1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mntk_fn_jacobian_contraction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mk_1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mXlaRuntimeError\u001B[0m: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter = (f32[3,3,512,512000]{1,0,2,3}, u8[0]{0}) custom-call(f32[1,7,7,512]{2,1,3,0} %bitcast.566, f32[1,7,7,512000]{2,1,3,0} %bitcast.1618), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(ntk_fn)/jit(main)/vmap(vmap(transpose(jvp(_ResNet))))/_ResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(1, 7, 7, 512) rhs_shape=(1, 7, 7, 512000) precision=None preferred_element_type=None]\" source_file=\"third_party/py/flax/linen/linear.py\" source_line=411}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: INTERNAL: Failed to synchronize GPU for autotuning conv instruction: (f32[3,3,512,512000]{1,0,2,3}, u8[0]{0}) custom-call(f32[1,7,7,512]{2,1,3,0}, f32[1,7,7,512000]{2,1,3,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning."
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "# Jacobian contraction - OOM!\n",
    "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
    "print(k_1.shape)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "empirical_ntk_resnet.ipynb",
   "provenance": [
    {
     "file_id": "1Mo5LAGjHOIEs2KNGc4DGMyeumYbN9ycV",
     "timestamp": 1655442514361
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
