{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otnqBdyaYBrf"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/neural-tangents/blob/main/notebooks/experimental/empirical_ntk_resnet_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTt0UNQbk_Td"
      },
      "source": [
        "# Example of computing NTK of a **Tensorflow (Keras)** ResNet50 on ImageNet inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvXMUSdFjCqq"
      },
      "source": [
        "Tested on NVIDIA A100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxdetCnZH7xE"
      },
      "source": [
        "More examples: \n",
        "\n",
        "\n",
        "*   JAX (Flax):\n",
        "  * [FCN](https://colab.research.google.com/github/google/neural-tangents/blob/main/notebooks/empirical_ntk_fcn.ipynb)\n",
        "  * [ResNet18](https://colab.research.google.com/github/google/neural-tangents/blob/main/notebooks/empirical_ntk_resnet.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl2JyRE1hK-z"
      },
      "source": [
        "# Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx1xr9v5pyl0",
        "outputId": "d6586a6f-f74b-4543-8da7-1c33d0a46af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: A100-SXM4-40GB (UUID: GPU-097b69f8-fbcd-6775-82c1-4cfd355907e9)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need at least jaxlib-0.1.73 to avoid certain CUDA bugs when using `implementation=auto`\n",
        "!pip install -q --upgrade pip\n",
        "!pip install --upgrade jax[cuda11_cudnn805] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip install -q git+https://www.github.com/google/neural-tangents.git"
      ],
      "metadata": {
        "id": "ZlckZChsxTWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbW8KVnsPfVd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import neural_tangents as nt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)"
      ],
      "metadata": {
        "id": "CqxnhMKDE2Gf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow model definition"
      ],
      "metadata": {
        "id": "eqVgigfhDoHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(O: int) -> tf.Module:\n",
        "  return tf.keras.applications.resnet.ResNet50(classes=O, weights=None)"
      ],
      "metadata": {
        "id": "wdqBa3OQDf97"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXqlToEouqSc"
      },
      "source": [
        "# NTK functions declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lPh5LGz9JBK_"
      },
      "outputs": [],
      "source": [
        "def get_ntk_fns(O: int):\n",
        "  # Define a TF-Keras ResNet50 with `O` output logits.\n",
        "  f = get_model(O)\n",
        "  f.build((None, *input_shape))\n",
        "  _, params = nt.experimental.get_apply_fn_and_params(f)\n",
        "\n",
        "  kwargs = dict(\n",
        "      f=f,\n",
        "      trace_axes=(),\n",
        "      vmap_axes=0\n",
        "  )\n",
        "\n",
        "  # Different NTK implementations\n",
        "  jacobian_contraction = nt.experimental.empirical_ntk_fn_tf(\n",
        "      **kwargs, implementation=nt.NtkImplementation.JACOBIAN_CONTRACTION)\n",
        "  ntvp = nt.experimental.empirical_ntk_fn_tf(\n",
        "      **kwargs, implementation=nt.NtkImplementation.NTK_VECTOR_PRODUCTS)\n",
        "  str_derivatives = nt.experimental.empirical_ntk_fn_tf(\n",
        "      **kwargs, implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES)\n",
        "  auto = nt.experimental.empirical_ntk_fn_tf(\n",
        "      **kwargs, implementation=nt.NtkImplementation.AUTO)\n",
        "  \n",
        "  return params, (jacobian_contraction, ntvp, str_derivatives, auto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lWFC3QEgao4"
      },
      "source": [
        "# $\\color{blue}O = 8$ logit, batch size $\\color{red}N = 8$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbExWKkUg9ew"
      },
      "source": [
        "Structured derivatives compute NTK fastest. NTK-vector products are actually slower in this setting, due to costly forward pass relative to parameters size, and therefore scales poorly with batch size $\\color{red}N$. While it scales better with $\\color{blue}O$ than other methods, it's not enough to overcome the $\\color{red}N^2$ forward passes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bwhIZWqxKTlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9914d19f-5ccc-46f1-c665-1674d2e11fea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/neural_tangents/experimental/empirical_tf/empirical.py:215: UserWarning: This function is an early proof-of-concept.\n",
            "  warnings.warn('This function is an early proof-of-concept.')\n"
          ]
        }
      ],
      "source": [
        "O = 8\n",
        "N = 8\n",
        "\n",
        "# Input images x\n",
        "x1 = tf.random.normal((N, *input_shape))\n",
        "x2 = tf.random.normal((N, *input_shape))\n",
        "\n",
        "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zObT8WnPggFo",
        "outputId": "f2d97d14-961c-4b28-f457-28a7e541b1a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "# Jacobian contraction\n",
        "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
        "print(k_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW9gJJ4qggFp",
        "outputId": "9e1c94f4-ac6b-44b4-be90-dcab39d69a23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "# NTK-vector products\n",
        "k_2 = ntk_fn_ntvp(x1, x2, params)\n",
        "print(k_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFeWnqGQggFp",
        "outputId": "256886ad-a7fa-4476-9cfb-b97c9d98b0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "# Structured derivatives\n",
        "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
        "print(k_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q63v1L1aggFp",
        "outputId": "c180cf00-3895-4034-cf03-91425436e9b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.00024576858, shape=(), dtype=float32) tf.Tensor(0.0006717233, shape=(), dtype=float32) tf.Tensor(0.00086082943, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Make sure kernels agree.\n",
        "print(\n",
        "    tf.reduce_max(tf.abs(k_1 - k_2)) / tf.reduce_mean(tf.abs(k_1)), \n",
        "    tf.reduce_max(tf.abs(k_1 - k_3)) / tf.reduce_mean(tf.abs(k_1)),\n",
        "    tf.reduce_max(tf.abs(k_2 - k_3)) / tf.reduce_mean(tf.abs(k_2))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selects best method based on FLOPs at first call / compilation.\n",
        "# Takes about 3x more time to compile.\n",
        "# WARNING: due to an XLA issue, currently only works correctly on TPUs!\n",
        "# Wrong FLOPs for CPU/GPU of JITted functions.\n",
        "k_0 = ntk_fn_auto(x1, x2, params)\n",
        "print(k_0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMsFPSOr3DTE",
        "outputId": "53434e57-cece-4446-8306-688eb92ea03a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "impl=1, flops=17815195648.0\n",
            "impl=2, flops=61376139264.0\n",
            "impl=3, flops=17957609472.0\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diP7nkBuggFp",
        "outputId": "6c0f222b-994c-4836-c24c-dc4dbab0c912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 317 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "ntk_fn_jacobian_contraction(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wehCdvi2ggFp",
        "outputId": "7482da28-ed14-4366-989b-8e5da43507ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 484 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# Slower - forward pass (FP) is expensive relative to parameters.\n",
        "# Time cost scales poorly with batch size N.\n",
        "ntk_fn_ntvp(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrm53akVggFp",
        "outputId": "f64a3915-5972-46fb-c857-ffe6d6dedbdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 184 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# 2X faster!\n",
        "ntk_fn_str_derivatives(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "P1QtkBqLggFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9eb5b5-7c8b-4dbe-a50f-2af774529493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 324 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit \n",
        "# On TPU should match the fastest method.\n",
        "# On GPU/CPU, currently is broken, and may not be the fastest.\n",
        "ntk_fn_auto(x1, x2, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1DLRESpXg7L"
      },
      "source": [
        "# $\\color{blue}O = 128$ logits, batch size $\\color{red}N = 1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfoHOoT-gGy6"
      },
      "source": [
        "Both NTK-vector products and Structured derivatives compute NTK faster than Jacobian contraction. NTK-vector products incur no penalty when batch size $\\color{red}N = 1$, and leverage their beneficial scaling with large $\\color{blue}O = 128$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3oHBaAmDhBON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6253afa-8f09-404b-85d8-da7898055960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/neural_tangents/experimental/empirical_tf/empirical.py:215: UserWarning: This function is an early proof-of-concept.\n",
            "  warnings.warn('This function is an early proof-of-concept.')\n"
          ]
        }
      ],
      "source": [
        "O = 128\n",
        "N = 1\n",
        "\n",
        "# Input images x\n",
        "x1 = tf.random.normal((N, *input_shape))\n",
        "x2 = tf.random.normal((N, *input_shape))\n",
        "\n",
        "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc1bUvL-KrK9",
        "outputId": "237c9718-dd5d-45d2-fcfa-e621ee5472f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# Jacobian contraction\n",
        "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
        "print(k_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdNsmnjOKyp0",
        "outputId": "d47dfbec-818f-4868-88e6-1ed51046e3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# NTK-vector products\n",
        "k_2 = ntk_fn_ntvp(x1, x2, params)\n",
        "print(k_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw6HL260K26E",
        "outputId": "c69250eb-5d4c-4211-89c5-956241560740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# Structured derivatives\n",
        "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
        "print(k_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYG0fV9nOjnd",
        "outputId": "e15ad99f-9396-4570-831b-043a0de87dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.014025839, shape=(), dtype=float32) tf.Tensor(0.0051410757, shape=(), dtype=float32) tf.Tensor(0.0148538705, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Make sure kernels agree.\n",
        "print(\n",
        "    tf.reduce_max(tf.abs(k_1 - k_2)) / tf.reduce_mean(tf.abs(k_1)), \n",
        "    tf.reduce_max(tf.abs(k_1 - k_3)) / tf.reduce_mean(tf.abs(k_1)),\n",
        "    tf.reduce_max(tf.abs(k_2 - k_3)) / tf.reduce_mean(tf.abs(k_2))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "DyF4M5_HK5Fk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00648984-bbb2-4086-9610-38f521360c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "impl=1, flops=30326192128.0\n",
            "impl=2, flops=25741133824.0\n",
            "impl=3, flops=30259060736.0\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 84 calls to <function convert.<locals>.converted_fun at 0x7fb3006c1d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 84 calls to <function convert.<locals>.converted_fun at 0x7fb3006c1d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# Selects best method based on FLOPs at first call / compilation.\n",
        "# Takes about 3x more time to compile.\n",
        "# WARNING: due to an XLA issue, currently only works correctly on TPUs!\n",
        "# Wrong FLOPs for CPU/GPU of JITted functions.\n",
        "k_0 = ntk_fn_auto(x1, x2, params)\n",
        "print(k_0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g1IO71LLJlG",
        "outputId": "50548640-2e14-4a8a-e54c-a6e16d467427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 495 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "ntk_fn_jacobian_contraction(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEIPcXYRMys2",
        "outputId": "9ac83c1b-3c2b-47a8-80ce-43c80ede94ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 276 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# 2X faster!\n",
        "ntk_fn_ntvp(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVyUPA8xM1ot",
        "outputId": "b82ec2d1-6243-486e-b62d-44b74b14179b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 232 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# 2.5X faster!\n",
        "ntk_fn_str_derivatives(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "o81r3UHJM34_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b346e4-0140-455c-989a-4b63a4709e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 275 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit \n",
        "# On TPU should match the fastest method.\n",
        "# On GPU/CPU, currently is broken, and may not be the fastest.\n",
        "ntk_fn_auto(x1, x2, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh_aFUZFXm_C"
      },
      "source": [
        "# $\\color{blue}O = 1000$ logits, batch size $\\color{red}N = 1$, full NTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rs4KF07fjjv"
      },
      "source": [
        "Structured derivatives allows to compute full $1000\\times 1000$ ImageNet NTK. Other methods run out of memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Z4MpdSJ7hFsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e47f10b-2dd9-48bb-a4de-baaf06468df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/neural_tangents/experimental/empirical_tf/empirical.py:215: UserWarning: This function is an early proof-of-concept.\n",
            "  warnings.warn('This function is an early proof-of-concept.')\n"
          ]
        }
      ],
      "source": [
        "O = 1000\n",
        "N = 1\n",
        "\n",
        "# Input images x\n",
        "x1 = tf.random.normal((N, *input_shape))\n",
        "x2 = tf.random.normal((N, *input_shape))\n",
        "\n",
        "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynBEtkA7d_2G",
        "outputId": "5ef3642f-81da-43c6-a0f5-0488077f9753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 1000, 1000)\n"
          ]
        }
      ],
      "source": [
        "# Structured derivatives - fits in memory!\n",
        "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
        "print(k_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afniv9k2d_2H",
        "outputId": "16363413-13f0-488b-b4a9-07305f8b8a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 1.29 s per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "ntk_fn_str_derivatives(x1, x2, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "4Ou5a6y4zH5Q",
        "outputId": "c7297d33-c265-4c79-b889-a5ffc58b721c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-43ee9476f982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# NTK-vector products - OOM!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mk_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntk_fn_ntvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     keras_symbolic_tensors = [\n",
            "\u001b[0;31mUnknownError\u001b[0m: Failed to determine best cudnn convolution algorithm: RESOURCE_EXHAUSTED: Allocating 9437184000 bytes exceeds the memory limit of 4294967296 bytes.\n\nConvolution performance may be suboptimal.  To ignore this failure and try to use a fallback algorithm, use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning. [Op:__inference_converted_fun_1940145]"
          ]
        }
      ],
      "source": [
        "# NTK-vector products - OOM!\n",
        "k_3 = ntk_fn_ntvp(x1, x2, params)\n",
        "print(k_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "rjXRalQfd_2G",
        "outputId": "6357f07b-e1ef-4079-932b-bf31f7a8b046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-ae557f05f951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Jacobian contraction - OOM!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mk_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntk_fn_jacobian_contraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     keras_symbolic_tensors = [\n",
            "\u001b[0;31mUnknownError\u001b[0m: Failed to determine best cudnn convolution algorithm: RESOURCE_EXHAUSTED: Allocating 9437184000 bytes exceeds the memory limit of 4294967296 bytes.\n\nConvolution performance may be suboptimal.  To ignore this failure and try to use a fallback algorithm, use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning. [Op:__inference_converted_fun_2069598]"
          ]
        }
      ],
      "source": [
        "# Jacobian contraction - OOM!\n",
        "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
        "print(k_1.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "empirical_ntk_resnet_tf.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
